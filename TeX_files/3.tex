
	
	Общая идея: 
	
	Обычный автокодировщик кодировал нам как-то картинку в вектора. Этот вектор являлся "характеристиками" этого изображения. 
	
	Хотим чтобы характеристики были не просто какими-то числовыми значениями, но вероятностными распределениями. Этим мы делаем две вещи: включаем в модель неопределенность (пример: плачущий мальчик и Мона Лиза: насчет первого мы точно знаем, что он не улыбается, его распределение будет сдвинуто, а само распределение прижато к среднему, в тоже самое время насчет Мона Лизы мы до конца не понимаем, улыбается она или нет, и раздвигая границы распределения "улыбки" мы этот момент учитываем). 
	
	Задача:
	
	Хотим построить векторное представление картинок $\mathbb{R}^{d}$, но каждая отдельная картинка соответствует не отдельному числу, но распределению определенному в этом векторном пространстве. Следствие: картинка будет описываться не отдельным числом, но некоторой средней и дисперсией нормального распределения. Получившиееся представление есть набор из d распределений со своими средними и дисперсиями. 
	
	Что мы делаем: 
	
	Сэмплируем вектор Z из распределения для картинки x, построеного для конкретной картинки. После этого мой декодировщик берет z и превращает его в $\bar x$.  Добиваемся того, чтобы раскодированная картинка была, как можно ближе к x.
	
	
	\subsection{Кодировщик}
	
	Кодировщик представляет картинку в виде набора распределений, которые описываются средним и дисперсией (во время обучения используется логарифм дисперсии). 

	
	\subsection{Декодировщик}
	
	Из построенного распределения сэмплируем значения и декодировщик выдает нам картинку, которая похожа на оригинальную. 
