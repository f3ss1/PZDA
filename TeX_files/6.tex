$L(D,G) = -\displaystyle\frac{1}{n}\sum\limits_{x_{i} \in X}log D(x_{i}) -\displaystyle\frac{1}{n}\sum\limits_{z_{i} \in Z}log(1 - D(G(z_{i}))) \rightarrow \min_{G} \max_{D} L(D,G) $ \\

Здесь D -- дискриминатор, G -- генератор. В этой функции потерь мы отдельно считаем ошибку на реальных объектах ($x_{i}$) и сгенерированных объектах ($G(z_{i})$). Сначала мы хотим минимизировать этот функционал на дискриминаторе, хотим научить его лучше разделять объекты. Потом мы максимизируем функционал на параметрах генератора, то есть мы хотим сдвинуть ближе реальные и сгенерированные объекты. \\

При обучении: \\ 
\begin{itemize}\setlength\itemsep{0.2em}
    \item Генерируем n объектов из случайного шума 
    \item Выбираем случайно n реальных объектов \item Берем случайный шум, пропускаем через генератор, передаем это в дискриминатор. Получаем вероятность того, что наши сгенериррованные объекты принадлежат к реальным объектам (и то же самое делаем для самих реальных объектов). 
    \item Используем функцию потерь, чтобы обновить параметры дискриминатора. И так k раз 
    \item Делаем одну итерацию обучения генератора. Еще раз генерим случайный шум и отдаем его дискриминатору, еще раз считаем функцию потерь (при ГС по параметрам генератора нам нужно только второе слагаемое функции потерь, то есть будем смотреть только на то, как хорошо получилось разделить сгенерированные объекты). 
\end{itemize}

Сначала обучаем дискриминатор, он дает нам некую меру сходства (насколько два класса (реальные и сгенерированные изображения) похожи друг на друга). Потом исользуем эту меру сходства, чтобы обучить генератор, чтобы он сдвигался ближе к реальным изображениям. 
