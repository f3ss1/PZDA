В чем вообще проблема: минимизация Perceptual Loss напрямую для каких-то адекватных размеров изображений занимает большое время (порядок времени --- 4 минуты для изображения 1024x1024). Это с точки зрения пользователя плохая история.

В том случае, если стилевое изображение зафиксировано, мы можем не просто напрямую минимизировать Perceptual Loss, а обучить нейросеть на выборке таким образом, чтобы она принимала на вход изображение $x$, а ее выход минимизировал Perceptual Loss.

Изначально было: $L(x, S, \hat{y}) \rightarrow \min\limits_{\hat{y}}$

Теперь стало: $L(x, S, a_\theta(x)) \rightarrow \min\limits_{\theta}$

Здесь $x$ --- входное изображение (пытаемся приблизиться к нему по контенту), $S$ --- стилевое изображение (пытаемся приблизиться к нему по стилю), которое мы и фиксируем, $a_\theta$ --- модель с параметрами $\theta$, принимающая на вход входное изображение и выдающее стилизованное.

То есть фактически мы подбираем модель, которая на выходе бы давала картинку, хорошую с точки зрения Perceptual Loss. Вместо прямой оптимизации мы пытаемся обучить какое-то преобразование.

Подобный подход не позволит нам выиграть времени на обучении (все равно придется обучать сетку, а это требует время), но зато затем, с обученной сеткой, создание картинки с нужным стилем будет значительно быстрее.

Однако, если мы поменяем стилевое изображение, то сетку придется обучать новую (что в целом логично).